# fincore 详细重构建议

> 基于 `改进优化建议.md` 中的架构分析，本文给出**具体的、可执行的**重构步骤。
> 每个步骤包含：目标、涉及文件、具体代码变更、测试验证方法、风险评估。

---

## 阶段一：依赖清理 + 惰性导入 + 类型基础（P0，1-2周）

> 不改变任何公开 API，纯粹提升工程质量。每个子步骤都可独立提交。

### 1.1 清理 `requirements.txt` 和 `setup.py`

**目标**: 移除遗留依赖，将可选依赖分组，为未来的 `pyproject.toml` 迁移做准备。

**涉及文件**:
- `requirements.txt`
- `setup.py`

**具体变更**:

#### requirements.txt → 仅保留开发/测试用途

```
# requirements.txt — 开发环境依赖（pip install -r requirements.txt）
# 核心依赖由 setup.py / pyproject.toml 管理

# Testing
pytest>=6.0
pytest-xdist>=2.0
pytest-cov>=2.10
pytest-benchmark>=3.2
pytest-sugar>=0.9
parameterized

# Lint & Type Check
ruff>=0.4.0
mypy>=1.5

# Optional (for tearsheets)
matplotlib>=3.3
seaborn>=0.11
ipython>=7.0

# Optional (for bayesian)
pymc>=5.0

# Optional (for data loading)
pandas-datareader>=0.8.0
akshare

# Dev tools
setuptools
packaging
```

#### setup.py 变更

```python
install_requires = [
    "numpy>=1.17.0",
    "pandas>=0.25.0",
    "scipy>=1.3.0",
    # 移除 "six>=1.10" — Python 3.8+ 不需要
]

extras_require = {
    "dev": [
        "pytest>=6.0",
        "pytest-xdist>=2.0",
        "pytest-cov>=2.10",
        "ruff>=0.4.0",
        "mypy>=1.5",
    ],
    "viz": [
        "matplotlib>=3.3",
        "seaborn>=0.11",
        "ipython>=7.0",
    ],
    "bayesian": [
        "pymc>=5.0",
    ],
    "datareader": [
        "pandas-datareader>=0.8.0",
    ],
    "all": [
        "fincore[viz,bayesian,datareader]",
    ],
}
```

**验证**: `pip install -e .` 成功；`pytest tests -n 8` 全部通过。

**风险**: 低。仅改变安装元数据，不影响运行时行为。

---

### 1.2 惰性导入 `fincore/__init__.py`

**目标**: `import fincore` 不再触发 matplotlib/seaborn/pymc 的导入链。

**当前代码** (`fincore/__init__.py`):
```python
__version__ = "0.1"
import numpy as _np
if not hasattr(_np, "unicode_"):
    _np.unicode_ = _np.str_
from .empyrical import Empyrical
try:
    from .pyfolio import Pyfolio
    __all__ = ["Empyrical", "Pyfolio"]
except ImportError:
    __all__ = ["Empyrical"]
```

**重构后**:
```python
__version__ = "0.1"

# NumPy 2.0 compat shim
import numpy as _np
if not hasattr(_np, "unicode_"):
    _np.unicode_ = _np.str_

__all__ = ["Empyrical", "Pyfolio", "analyze"]

def __getattr__(name):
    """Lazy imports to avoid loading matplotlib/seaborn/pymc on import."""
    if name == "Empyrical":
        from .empyrical import Empyrical
        globals()["Empyrical"] = Empyrical
        return Empyrical
    if name == "Pyfolio":
        from .pyfolio import Pyfolio
        globals()["Pyfolio"] = Pyfolio
        return Pyfolio
    if name == "analyze":
        from .core.context import analyze
        globals()["analyze"] = analyze
        return analyze
    raise AttributeError(f"module 'fincore' has no attribute {name}")
```

**惰性导入 `metrics/__init__.py`**:

同理，将 17 个子模块全量导入改为惰性导入：

```python
"""Metrics - 拆分后的金融性能分析函数模块."""

import importlib

_MODULE_MAP = {
    'basic_module': 'fincore.metrics.basic',
    'returns_module': 'fincore.metrics.returns',
    'drawdown_module': 'fincore.metrics.drawdown',
    'risk_module': 'fincore.metrics.risk',
    'ratios_module': 'fincore.metrics.ratios',
    'alpha_beta_module': 'fincore.metrics.alpha_beta',
    'stats_module': 'fincore.metrics.stats',
    'consecutive_module': 'fincore.metrics.consecutive',
    'rolling_module': 'fincore.metrics.rolling',
    'bayesian_module': 'fincore.metrics.bayesian',
    'positions_module': 'fincore.metrics.positions',
    'transactions_module': 'fincore.metrics.transactions',
    'round_trips_module': 'fincore.metrics.round_trips',
    'perf_attrib_module': 'fincore.metrics.perf_attrib',
    'perf_stats_module': 'fincore.metrics.perf_stats',
    'timing_module': 'fincore.metrics.timing',
    'yearly_module': 'fincore.metrics.yearly',
}

def __getattr__(name):
    if name in _MODULE_MAP:
        mod = importlib.import_module(_MODULE_MAP[name])
        globals()[name] = mod
        return mod
    raise AttributeError(f"module 'fincore.metrics' has no attribute {name}")
```

**验证**:
```python
import time
t0 = time.time(); import fincore; print(f"{time.time()-t0:.3f}s")
# 目标: < 0.1s（当前约 1-2s）
# 然后：
t0 = time.time(); fincore.Empyrical.sharpe_ratio(returns); print(f"{time.time()-t0:.3f}s")
# 第一次调用会触发实际导入，后续调用无额外开销
```

**风险**: 中。需要确保所有 `from fincore.metrics import xxx_module` 的引用点都兼容惰性加载。`empyrical.py` 的顶层导入需要同步改为函数内导入或使用 `__getattr__`。

**回退方案**: 如果惰性导入引发循环导入问题，可以仅对 `pyfolio.py`（包含 matplotlib 等重量级依赖）做惰性导入，`metrics` 保持即时导入。

---

### 1.3 创建类型定义文件 `fincore/_types.py`

**目标**: 建立统一的类型别名和结构化返回类型。

**新建文件** `fincore/_types.py`:

```python
"""Type definitions for fincore."""
from __future__ import annotations

from typing import NamedTuple, Optional, Union, Sequence
import numpy as np
import pandas as pd

# ---------------------------------------------------------------------------
# 输入类型别名
# ---------------------------------------------------------------------------
ArrayLike = Union[pd.Series, np.ndarray, Sequence[float]]
ReturnSeries = Union[pd.Series, np.ndarray]
ReturnOrDataFrame = Union[pd.Series, pd.DataFrame, np.ndarray]

# ---------------------------------------------------------------------------
# 结构化返回类型
# ---------------------------------------------------------------------------
class DrawdownPeriod(NamedTuple):
    """A single drawdown period with peak, valley, and recovery dates."""
    peak: pd.Timestamp
    valley: pd.Timestamp
    recovery: Optional[pd.Timestamp]

class AlphaBeta(NamedTuple):
    """Alpha and beta pair."""
    alpha: float
    beta: float

class RollingAlphaBeta(NamedTuple):
    """Rolling alpha and beta series."""
    alpha: pd.Series
    beta: pd.Series

class BootstrapResult(NamedTuple):
    """Bootstrap analysis result."""
    samples: np.ndarray
    mean: float
    median: float
    ci_lower: float  # 5th percentile
    ci_upper: float  # 95th percentile

# ---------------------------------------------------------------------------
# 常量类型
# ---------------------------------------------------------------------------
Period = str  # 'daily', 'weekly', 'monthly', 'yearly'
```

**逐步应用**: 从 `metrics/alpha_beta.py` 开始，将 `alpha_beta()` 和 `alpha_beta_aligned()` 的返回类型从 `tuple` 改为 `AlphaBeta`：

```python
# metrics/alpha_beta.py
from fincore._types import AlphaBeta

def alpha_beta_aligned(returns, factor_returns, ...) -> AlphaBeta:
    ...
    return AlphaBeta(alpha=alpha_val, beta=beta_val)
```

**向后兼容**: `NamedTuple` 完全兼容 tuple 解构，所以 `a, b = alpha_beta(...)` 仍然有效。

**验证**: 现有测试应全部通过，因为 `NamedTuple` 向后兼容 `tuple`。

---

### 1.4 添加 type hints（逐文件推进）

**推荐顺序**（按依赖深度，从底层开始）:

1. `fincore/constants/periods.py` — 纯常量
2. `fincore/utils/math_utils.py` — `nanmean`, `nanstd` 等
3. `fincore/metrics/basic.py` — `aligned_series`, `annualization_factor` 等
4. `fincore/metrics/returns.py` — `cum_returns`, `simple_returns` 等
5. `fincore/metrics/drawdown.py` — 使用 `DrawdownPeriod`
6. `fincore/metrics/risk.py`
7. `fincore/metrics/ratios.py`
8. `fincore/metrics/alpha_beta.py` — 使用 `AlphaBeta`
9. 其余 metrics 模块
10. `fincore/empyrical.py`

**示例** (`metrics/basic.py`):

```python
from __future__ import annotations
import numpy as np
import pandas as pd
from fincore._types import ArrayLike, ReturnSeries, Period

def annualization_factor(period: Period, annualization: float | None) -> float:
    ...

def adjust_returns(returns: ReturnSeries, adjustment_factor: float) -> ReturnSeries:
    ...

def aligned_series(*many_series: pd.Series) -> tuple[pd.Series, ...]:
    ...
```

**验证**: 配置 `mypy`，逐模块启用 strict 模式:

```ini
# mypy.ini
[mypy]
python_version = 3.10
warn_return_any = True
warn_unused_configs = True

[mypy-fincore.metrics.basic]
disallow_untyped_defs = True

[mypy-fincore.metrics.returns]
disallow_untyped_defs = True

# 逐步扩展到所有模块...
```

---

### 1.5 迁移到 `pyproject.toml`（可选，与 1.1 合并）

**新建** `pyproject.toml`：

```toml
[build-system]
requires = ["setuptools>=68.0", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "fincore"
version = "0.1.0"
description = "Quantitative performance and risk analytics for Python"
readme = "README.md"
license = {text = "MIT"}
requires-python = ">=3.8"
authors = [
    {name = "cloudQuant", email = "yunjinqi@gmail.com"},
]
classifiers = [
    "Development Status :: 4 - Beta",
    "Programming Language :: Python :: 3",
    "License :: OSI Approved :: MIT License",
    "Intended Audience :: Science/Research",
    "Topic :: Scientific/Engineering :: Mathematics",
]
dependencies = [
    "numpy>=1.17.0",
    "pandas>=0.25.0",
    "scipy>=1.3.0",
]

[project.optional-dependencies]
viz = ["matplotlib>=3.3", "seaborn>=0.11", "ipython>=7.0"]
bayesian = ["pymc>=5.0"]
datareader = ["pandas-datareader>=0.8.0"]
dev = [
    "pytest>=6.0",
    "pytest-xdist>=2.0",
    "pytest-cov>=2.10",
    "pytest-benchmark>=3.2",
    "parameterized",
    "ruff>=0.4.0",
    "mypy>=1.5",
]
all = ["fincore[viz,bayesian,datareader]"]

[project.urls]
Homepage = "https://github.com/cloudQuant/fincore"

[tool.setuptools.packages.find]
include = ["fincore*"]

[tool.mypy]
python_version = "3.10"
warn_return_any = true
warn_unused_configs = true

[tool.ruff]
target-version = "py38"
line-length = 120

[tool.ruff.lint]
select = ["E", "F", "I", "UP", "B", "SIM"]

[tool.pytest.ini_options]
testpaths = ["tests"]
addopts = "-q --tb=short"
```

**操作**: 将 `setup.py` 中的元数据迁移到 `pyproject.toml` 后，`setup.py` 可简化为空壳或删除。

---

## 阶段二：AnalysisContext 缓存层（P1，2-3周）

> 核心重构：引入计算上下文，消除 `perf_stats` 和 tearsheet 中的重复计算。

### 2.1 新建 `fincore/core/` 目录

```
fincore/core/
├── __init__.py
├── context.py        # AnalysisContext
└── engine.py         # RollingEngine (阶段三)
```

### 2.2 实现 `AnalysisContext`

**新建文件** `fincore/core/context.py`:

```python
"""Core analysis context with lazy computation and caching."""
from __future__ import annotations

from functools import cached_property
from typing import Optional

import numpy as np
import pandas as pd

from fincore.constants import DAILY


class AnalysisContext:
    """Lazy-compute and cache analytics results for a returns series.

    所有计算结果通过 ``cached_property`` 实现惰性求值 + 自动缓存。
    同一份数据只计算一次，后续访问直接返回缓存值。

    Parameters
    ----------
    returns : pd.Series
        日频非累计收益序列。
    factor_returns : pd.Series, optional
        基准收益序列。
    positions : pd.DataFrame, optional
        每日持仓。
    transactions : pd.DataFrame, optional
        交易记录。
    risk_free : float
        无风险利率，默认 0.0。
    period : str
        数据频率，默认 'daily'。

    Examples
    --------
    >>> ctx = AnalysisContext(returns, factor_returns=benchmark)
    >>> ctx.sharpe_ratio   # 第一次计算并缓存
    1.23
    >>> ctx.sharpe_ratio   # 直接返回缓存值
    1.23
    >>> ctx.perf_stats()   # 汇总所有指标，内部复用缓存
    Annual return     0.15
    Max drawdown     -0.08
    Sharpe ratio      1.23
    ...
    """

    def __init__(
        self,
        returns: pd.Series,
        factor_returns: Optional[pd.Series] = None,
        positions: Optional[pd.DataFrame] = None,
        transactions: Optional[pd.DataFrame] = None,
        risk_free: float = 0.0,
        period: str = DAILY,
    ):
        self.returns = returns
        self.factor_returns = factor_returns
        self.positions = positions
        self.transactions = transactions
        self.risk_free = risk_free
        self.period = period

    # ------------------------------------------------------------------
    # 中间结果缓存
    # ------------------------------------------------------------------

    @cached_property
    def _returns_array(self) -> np.ndarray:
        return np.asanyarray(self.returns)

    @cached_property
    def _ann_factor(self) -> float:
        from fincore.metrics.basic import annualization_factor
        return annualization_factor(self.period, None)

    @cached_property
    def cum_returns(self) -> pd.Series:
        from fincore.metrics.returns import cum_returns
        return cum_returns(self.returns, starting_value=1.0)

    @cached_property
    def _underwater(self) -> pd.Series:
        running_max = self.cum_returns.expanding().max()
        return self.cum_returns / running_max - 1

    # ------------------------------------------------------------------
    # 核心指标（缓存）
    # ------------------------------------------------------------------

    @cached_property
    def annual_return(self) -> float:
        from fincore.metrics.yearly import annual_return
        return annual_return(self.returns, self.period)

    @cached_property
    def cumulative_return(self) -> float:
        from fincore.metrics.returns import cum_returns_final
        return cum_returns_final(self.returns, starting_value=0)

    @cached_property
    def annual_volatility(self) -> float:
        from fincore.metrics.risk import annual_volatility
        return annual_volatility(self.returns, self.period)

    @cached_property
    def max_drawdown(self) -> float:
        from fincore.metrics.drawdown import max_drawdown
        return max_drawdown(self.returns)

    @cached_property
    def sharpe_ratio(self) -> float:
        from fincore.metrics.ratios import sharpe_ratio
        return sharpe_ratio(self.returns, self.risk_free, self.period)

    @cached_property
    def sortino_ratio(self) -> float:
        from fincore.metrics.ratios import sortino_ratio
        return sortino_ratio(self.returns, period=self.period)

    @cached_property
    def calmar_ratio(self) -> float:
        from fincore.metrics.ratios import calmar_ratio
        return calmar_ratio(self.returns, period=self.period)

    @cached_property
    def omega_ratio(self) -> float:
        from fincore.metrics.ratios import omega_ratio
        return omega_ratio(self.returns, self.risk_free)

    @cached_property
    def stability(self) -> float:
        from fincore.metrics.ratios import stability_of_timeseries
        return stability_of_timeseries(self.returns)

    @cached_property
    def skewness(self) -> float:
        from fincore.metrics.stats import skewness
        return skewness(self.returns)

    @cached_property
    def kurtosis(self) -> float:
        from fincore.metrics.stats import kurtosis
        return kurtosis(self.returns)

    @cached_property
    def tail_ratio(self) -> float:
        from fincore.metrics.risk import tail_ratio
        return tail_ratio(self.returns)

    @cached_property
    def daily_var(self) -> float:
        from fincore.metrics.risk import value_at_risk
        return value_at_risk(self.returns)

    @cached_property
    def alpha_beta(self) -> tuple:
        if self.factor_returns is None:
            return (np.nan, np.nan)
        from fincore.metrics.alpha_beta import alpha_beta
        return alpha_beta(self.returns, self.factor_returns,
                         self.risk_free, self.period)

    @cached_property
    def alpha(self) -> float:
        return self.alpha_beta[0]

    @cached_property
    def beta(self) -> float:
        return self.alpha_beta[1]

    @cached_property
    def top_drawdowns(self) -> list:
        from fincore.metrics.drawdown import get_top_drawdowns
        return get_top_drawdowns(self.returns, top=10)

    @cached_property
    def drawdown_table(self) -> pd.DataFrame:
        from fincore.metrics.drawdown import gen_drawdown_table
        return gen_drawdown_table(self.returns, top=10)

    # ------------------------------------------------------------------
    # 汇总方法
    # ------------------------------------------------------------------

    def perf_stats(self) -> pd.Series:
        """计算综合绩效统计。所有子指标通过 cached_property 缓存，无重复计算。"""
        from collections import OrderedDict
        stats = OrderedDict()
        stats['Annual return'] = self.annual_return
        stats['Cumulative returns'] = self.cumulative_return
        stats['Annual volatility'] = self.annual_volatility
        stats['Sharpe ratio'] = self.sharpe_ratio
        stats['Calmar ratio'] = self.calmar_ratio
        stats['Stability'] = self.stability
        stats['Max drawdown'] = self.max_drawdown
        stats['Omega ratio'] = self.omega_ratio
        stats['Sortino ratio'] = self.sortino_ratio
        stats['Skew'] = self.skewness
        stats['Kurtosis'] = self.kurtosis
        stats['Tail ratio'] = self.tail_ratio
        stats['Daily value at risk'] = self.daily_var
        if self.factor_returns is not None:
            stats['Alpha'] = self.alpha
            stats['Beta'] = self.beta
        return pd.Series(stats)

    def invalidate(self):
        """清除所有缓存（数据更新后调用）。"""
        cls = type(self)
        for attr in list(self.__dict__):
            if isinstance(getattr(cls, attr, None), cached_property):
                del self.__dict__[attr]

    # ------------------------------------------------------------------
    # 便捷方法
    # ------------------------------------------------------------------

    def to_dict(self) -> dict:
        """将所有指标导出为字典。"""
        return self.perf_stats().to_dict()

    def to_json(self, path: str = None) -> str:
        """将所有指标导出为 JSON。"""
        import json
        data = {k: (float(v) if isinstance(v, (np.floating, float)) else v)
                for k, v in self.to_dict().items()}
        result = json.dumps(data, indent=2, ensure_ascii=False)
        if path:
            with open(path, 'w') as f:
                f.write(result)
        return result

    def __repr__(self) -> str:
        n = len(self.returns)
        start = self.returns.index[0] if n > 0 else 'N/A'
        end = self.returns.index[-1] if n > 0 else 'N/A'
        return (f"AnalysisContext(n={n}, period={self.period}, "
                f"range=[{start}, {end}])")


def analyze(returns, factor_returns=None, **kwargs) -> AnalysisContext:
    """创建 AnalysisContext 的便捷函数。

    Examples
    --------
    >>> import fincore
    >>> ctx = fincore.analyze(returns, factor_returns=benchmark)
    >>> print(ctx.sharpe_ratio)
    >>> print(ctx.perf_stats())
    """
    return AnalysisContext(returns, factor_returns=factor_returns, **kwargs)
```

**新建文件** `fincore/core/__init__.py`:

```python
"""Core computation engine."""
from fincore.core.context import AnalysisContext, analyze

__all__ = ['AnalysisContext', 'analyze']
```

### 2.3 集成到 `Empyrical` 类（向后兼容）

在 `empyrical.py` 的 `__init__` 中可选创建 context：

```python
class Empyrical:
    def __init__(self, returns=None, positions=None, factor_returns=None,
                 factor_loadings=None, **kwargs):
        self.returns = returns
        self.positions = positions
        self.factor_returns = factor_returns
        self.factor_loadings = factor_loadings
        # 新增：如果提供了 returns，创建缓存上下文
        self._ctx = None
        if returns is not None:
            from fincore.core.context import AnalysisContext
            self._ctx = AnalysisContext(
                returns, factor_returns=factor_returns,
                positions=positions,
                risk_free=kwargs.get('risk_free', 0.0),
                period=kwargs.get('period', DAILY),
            )
```

**不修改现有方法签名**，仅在 `_dual_method` 修饰的实例方法中优先查缓存：

```python
# 示例：修改后的 perf_stats
@classmethod
def perf_stats(cls, returns, factor_returns=None, positions=None,
               transactions=None, turnover_denom='AGB', period=DAILY):
    # 如果是实例调用且有缓存上下文，直接用缓存版本
    if not isinstance(cls, type) and hasattr(cls, '_ctx') and cls._ctx is not None:
        if returns is None or returns is cls.returns:
            return cls._ctx.perf_stats()
    # 否则走原有路径
    return _perf_stats.perf_stats(returns, factor_returns, positions,
                                   transactions, turnover_denom, period)
```

**验证**: `pytest tests -n 8` 全部通过。额外编写性能测试：

```python
# tests/test_context.py
import time
import pandas as pd
import numpy as np
from fincore.core.context import AnalysisContext

def test_context_perf_stats_no_redundant_compute():
    """perf_stats through context should be faster than standalone."""
    np.random.seed(42)
    returns = pd.Series(np.random.randn(2520) * 0.01,
                        index=pd.bdate_range('2010-01-01', periods=2520))
    benchmark = pd.Series(np.random.randn(2520) * 0.008,
                          index=returns.index)

    ctx = AnalysisContext(returns, factor_returns=benchmark)

    t0 = time.time()
    stats1 = ctx.perf_stats()
    t_ctx = time.time() - t0

    # 再次调用，应该极快（全部缓存）
    t0 = time.time()
    stats2 = ctx.perf_stats()
    t_cached = time.time() - t0

    assert t_cached < t_ctx * 0.1  # 缓存版本至少快10x
    pd.testing.assert_series_equal(stats1, stats2)

def test_context_invalidate():
    """After invalidate(), values should be recomputed."""
    np.random.seed(42)
    returns = pd.Series(np.random.randn(252) * 0.01,
                        index=pd.bdate_range('2020-01-01', periods=252))
    ctx = AnalysisContext(returns)
    sr1 = ctx.sharpe_ratio
    ctx.invalidate()
    sr2 = ctx.sharpe_ratio
    assert sr1 == sr2  # 相同数据应得到相同结果
```

---

## 阶段三：滚动计算向量化（P1，1-2周）

### 3.1 向量化 `roll_max_drawdown`

**当前代码** (`metrics/rolling.py:254-295`): Python for 循环逐窗口计算。

**重构后**:

```python
def roll_max_drawdown(returns, window=252):
    """Calculate rolling maximum drawdown — vectorized version."""
    is_series = isinstance(returns, pd.Series)

    if len(returns) < window:
        if is_series:
            if isinstance(returns.index, pd.DatetimeIndex):
                return pd.Series([], dtype=float, index=pd.DatetimeIndex([]))
            return pd.Series([], dtype=float)
        return np.array([], dtype=float)

    ret_arr = np.asanyarray(returns)

    # 使用 sliding_window_view 批量切片（NumPy >= 1.20）
    from numpy.lib.stride_tricks import sliding_window_view
    windows = sliding_window_view(ret_arr, window)  # shape: (n-w+1, w)

    # 批量计算每个窗口的 cumulative returns
    cum = np.cumprod(1.0 + windows, axis=1)

    # 批量计算每个窗口的 running max
    running_max = np.maximum.accumulate(cum, axis=1)

    # 批量计算每个窗口的 underwater
    with np.errstate(divide='ignore', invalid='ignore'):
        underwater = cum / running_max - 1.0

    # 每个窗口的最小值即为该窗口的最大回撤
    out = np.nanmin(underwater, axis=1)

    if is_series:
        return pd.Series(out, index=returns.index[window - 1:])
    else:
        return out
```

**注意**: `sliding_window_view` 需要 NumPy >= 1.20。对于大窗口 + 长序列，内存占用 = `(n - w + 1) * w * 8` 字节。对于 2520 天 + 252 窗口 = ~4.6MB，完全可接受。

**回退方案**: 如果内存成为问题（百万级数据），可分块计算：

```python
CHUNK = 10000
for start in range(0, n, CHUNK):
    chunk_windows = sliding_window_view(ret_arr[start:start+CHUNK+window-1], window)
    # ... 同上逻辑
```

**验证**:
```python
def test_roll_max_drawdown_matches_original():
    """Ensure vectorized version matches loop version."""
    np.random.seed(42)
    returns = pd.Series(np.random.randn(500) * 0.01,
                        index=pd.bdate_range('2020-01-01', periods=500))
    result_new = roll_max_drawdown(returns, window=60)
    # 对比原始 for 循环版本的结果
    result_old = _roll_max_drawdown_loop(returns, window=60)
    np.testing.assert_allclose(result_new.values, result_old.values, rtol=1e-12)
```

### 3.2 向量化 `roll_beta`（已实现，确认）

当前 `roll_beta` 已使用 `pd.rolling().cov()` / `.var()` 向量化，无需修改。

### 3.3 批量滚动引擎（统一多指标计算）

**新建文件** `fincore/core/engine.py`:

```python
"""Batch rolling computation engine."""
from __future__ import annotations

import numpy as np
import pandas as pd

from fincore.constants import DAILY
from fincore.metrics.basic import annualization_factor, aligned_series


class RollingEngine:
    """Single-pass rolling computation for multiple metrics.

    当 tearsheet 需要同时计算 roll_alpha + roll_beta + roll_sharpe +
    roll_max_drawdown 时，使用 RollingEngine 可以只遍历窗口一次。

    Parameters
    ----------
    returns : pd.Series
        策略收益序列。
    factor_returns : pd.Series, optional
        基准收益序列。
    window : int
        滚动窗口大小（默认 252）。
    risk_free : float
        无风险利率（默认 0.0）。
    period : str
        数据频率（默认 'daily'）。

    Examples
    --------
    >>> engine = RollingEngine(returns, factor_returns=benchmark, window=252)
    >>> results = engine.compute(['sharpe', 'beta', 'max_drawdown'])
    >>> results['sharpe']  # pd.Series
    >>> results['beta']    # pd.Series
    """

    _VECTORIZABLE = {'sharpe', 'beta', 'volatility', 'max_drawdown'}
    _LOOP_ONLY = {'alpha', 'alpha_beta', 'up_capture', 'down_capture'}

    def __init__(self, returns, factor_returns=None, window=252,
                 risk_free=0.0, period=DAILY):
        self.returns = returns
        self.factor_returns = factor_returns
        self.window = window
        self.risk_free = risk_free
        self.period = period
        self._ann_factor = annualization_factor(period, None)

        if factor_returns is not None:
            self._ret_aligned, self._fac_aligned = aligned_series(
                returns, factor_returns)
        else:
            self._ret_aligned = returns
            self._fac_aligned = None

    def compute(self, metrics: list[str]) -> dict[str, pd.Series]:
        """Compute multiple rolling metrics efficiently.

        对于可向量化的指标，使用 pandas rolling 或 numpy stride views。
        对于不可向量化的指标（如 alpha），使用 for 循环但在同一次遍历中计算。
        """
        results = {}
        vec_metrics = [m for m in metrics if m in self._VECTORIZABLE]
        loop_metrics = [m for m in metrics if m in self._LOOP_ONLY]

        # 批量向量化计算
        for m in vec_metrics:
            results[m] = self._compute_vectorized(m)

        # 单次循环计算所有 loop-only 指标
        if loop_metrics:
            loop_results = self._compute_loop(loop_metrics)
            results.update(loop_results)

        return results

    def _compute_vectorized(self, metric: str) -> pd.Series:
        w = self.window
        if metric == 'sharpe':
            from fincore.metrics.rolling import roll_sharpe_ratio
            return roll_sharpe_ratio(self.returns, w, self.risk_free,
                                     self.period)
        elif metric == 'beta':
            from fincore.metrics.rolling import roll_beta
            return roll_beta(self.returns, self.factor_returns, w,
                            self.risk_free)
        elif metric == 'volatility':
            from fincore.metrics.rolling import rolling_volatility
            return rolling_volatility(self.returns, w, self.period)
        elif metric == 'max_drawdown':
            from fincore.metrics.rolling import roll_max_drawdown
            return roll_max_drawdown(self.returns, w)

    def _compute_loop(self, metrics: list[str]) -> dict[str, pd.Series]:
        """Single for-loop computing multiple non-vectorizable metrics."""
        from fincore.metrics.alpha_beta import (
            alpha_aligned, alpha_beta_aligned)
        from fincore.metrics.ratios import up_capture, down_capture

        ret_aligned = self._ret_aligned
        fac_aligned = self._fac_aligned
        w = self.window
        n = len(ret_aligned) - w + 1

        if n <= 0:
            return {m: pd.Series([], dtype=float) for m in metrics}

        arrays = {m: np.empty(n, dtype=float) for m in metrics}
        ret_arr = np.asanyarray(ret_aligned)
        fac_arr = np.asanyarray(fac_aligned) if fac_aligned is not None else None

        for i in range(n):
            r = ret_arr[i:i + w]
            f = fac_arr[i:i + w] if fac_arr is not None else None

            for m in metrics:
                if m == 'alpha' and f is not None:
                    arrays[m][i] = alpha_aligned(
                        r, f, self.risk_free, self.period)
                elif m == 'alpha_beta' and f is not None:
                    ab = alpha_beta_aligned(
                        r, f, self.risk_free, self.period)
                    arrays.setdefault('alpha', np.empty(n))[i] = ab[0]
                    arrays.setdefault('beta_loop', np.empty(n))[i] = ab[1]
                elif m == 'up_capture' and f is not None:
                    arrays[m][i] = up_capture(
                        pd.Series(r), pd.Series(f))
                elif m == 'down_capture' and f is not None:
                    arrays[m][i] = down_capture(
                        pd.Series(r), pd.Series(f))

        idx = ret_aligned.index[w - 1:] if isinstance(
            ret_aligned, pd.Series) else None
        return {m: pd.Series(arrays[m], index=idx) for m in arrays
                if m in metrics}
```

**使用示例**:
```python
from fincore.core.engine import RollingEngine

engine = RollingEngine(returns, benchmark, window=252)
# 一次遍历同时计算 alpha + up_capture + down_capture
results = engine.compute(['alpha', 'up_capture', 'down_capture'])
```

---

## 阶段四：可视化解耦（P2，3-4周）

### 4.1 设计可视化后端协议

**新建文件** `fincore/viz/__init__.py`:

```python
"""Visualization backends for fincore."""
from fincore.viz.base import VizBackend

__all__ = ['VizBackend']
```

**新建文件** `fincore/viz/base.py`:

```python
"""Abstract visualization backend protocol."""
from __future__ import annotations
from typing import Protocol, Optional, Any

class VizBackend(Protocol):
    """Protocol for visualization backends."""

    def plot_cumulative_returns(self, cum_returns, benchmark_cum=None,
                                 title=None, **kwargs) -> Any: ...

    def plot_drawdown_underwater(self, underwater, **kwargs) -> Any: ...

    def plot_rolling_metric(self, series, metric_name, **kwargs) -> Any: ...

    def plot_monthly_heatmap(self, monthly_returns, **kwargs) -> Any: ...

    def plot_annual_returns(self, annual_returns, **kwargs) -> Any: ...

    def show_perf_stats_table(self, stats, **kwargs) -> Any: ...
```

### 4.2 Matplotlib 后端（包装现有 tearsheets 函数）

**新建文件** `fincore/viz/matplotlib_backend.py`:

```python
"""Matplotlib visualization backend — wraps existing tearsheets functions."""
from __future__ import annotations

class MatplotlibBackend:
    """Matplotlib-based visualization backend.

    Delegates to existing fincore.tearsheets functions for backward
    compatibility while conforming to the VizBackend protocol.
    """

    def plot_cumulative_returns(self, cum_returns, benchmark_cum=None,
                                 title=None, ax=None, **kwargs):
        from fincore.tearsheets.returns import plot_rolling_returns
        return plot_rolling_returns(cum_returns - 1, ax=ax, **kwargs)

    def plot_drawdown_underwater(self, underwater, ax=None, **kwargs):
        from fincore.tearsheets.returns import plot_drawdown_underwater
        return plot_drawdown_underwater(underwater, ax=ax, **kwargs)

    def plot_monthly_heatmap(self, monthly_returns, ax=None, **kwargs):
        from fincore.tearsheets.returns import plot_monthly_returns_heatmap
        return plot_monthly_returns_heatmap(monthly_returns, ax=ax, **kwargs)

    def show_perf_stats_table(self, stats, **kwargs):
        from fincore.tearsheets.returns import show_perf_stats
        return show_perf_stats(stats, **kwargs)
```

### 4.3 在 AnalysisContext 中集成可视化

```python
# core/context.py 新增方法

class AnalysisContext:
    ...

    def plot(self, backend='matplotlib', metrics=None, **kwargs):
        """Generate visualization using specified backend.

        Parameters
        ----------
        backend : str or VizBackend
            'matplotlib', 'plotly', or a VizBackend instance.
        metrics : list of str, optional
            Specific plots to generate. Default generates all.
        """
        if isinstance(backend, str):
            if backend == 'matplotlib':
                from fincore.viz.matplotlib_backend import MatplotlibBackend
                backend = MatplotlibBackend()
            elif backend == 'plotly':
                from fincore.viz.plotly_backend import PlotlyBackend
                backend = PlotlyBackend()
            else:
                raise ValueError(f"Unknown backend: {backend}")

        backend.plot_cumulative_returns(self.cum_returns)
        backend.plot_drawdown_underwater(self._underwater)
        backend.show_perf_stats_table(self.perf_stats())
```

### 4.4 HTML 报告生成器

**新建文件** `fincore/viz/html_backend.py`:

```python
"""HTML report generator."""
from __future__ import annotations
import base64
from io import BytesIO

class HtmlReportBuilder:
    """Generate a self-contained HTML report from AnalysisContext."""

    def __init__(self, ctx):
        self.ctx = ctx
        self._sections = []

    def add_stats_table(self):
        stats = self.ctx.perf_stats()
        html = stats.to_frame('Value').to_html(
            classes='stats-table', float_format='{:.4f}'.format)
        self._sections.append(('Performance Summary', html))
        return self

    def add_chart(self, title, fig):
        """Embed a matplotlib figure as base64 PNG."""
        buf = BytesIO()
        fig.savefig(buf, format='png', dpi=100, bbox_inches='tight')
        buf.seek(0)
        img_data = base64.b64encode(buf.read()).decode('utf-8')
        html = f'<img src="data:image/png;base64,{img_data}" />'
        self._sections.append((title, html))
        return self

    def build(self) -> str:
        """Build complete HTML document."""
        sections_html = ''
        for title, content in self._sections:
            sections_html += f'<h2>{title}</h2>\n{content}\n'
        return _HTML_TEMPLATE.format(
            title='Fincore Analysis Report',
            body=sections_html,
        )

    def save(self, path: str):
        html = self.build()
        with open(path, 'w', encoding='utf-8') as f:
            f.write(html)

_HTML_TEMPLATE = """<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <title>{title}</title>
    <style>
        body {{ font-family: -apple-system, BlinkMacSystemFont, sans-serif;
               max-width: 1200px; margin: 0 auto; padding: 20px; }}
        .stats-table {{ border-collapse: collapse; width: 100%; }}
        .stats-table td, .stats-table th {{
            border: 1px solid #ddd; padding: 8px; text-align: right; }}
        .stats-table th {{ background-color: #f5f5f5; }}
        img {{ max-width: 100%; margin: 10px 0; }}
        h2 {{ color: #333; border-bottom: 2px solid #eee; padding-bottom: 5px; }}
    </style>
</head>
<body>
    <h1>{title}</h1>
    {body}
</body>
</html>"""
```

**使用**:
```python
ctx = fincore.analyze(returns, factor_returns=benchmark)
from fincore.viz.html_backend import HtmlReportBuilder
report = HtmlReportBuilder(ctx)
report.add_stats_table()
# report.add_chart('Cumulative Returns', fig)  # optional
report.save('analysis_report.html')
```

---

## 阶段五：消除 God Class + 顶级 API（P2，2-3周）

### 5.1 新的用户入口

重构后，fincore 提供三层 API：

```python
# 层级1：极简 API（推荐）
import fincore
ctx = fincore.analyze(returns, factor_returns=benchmark)
ctx.sharpe_ratio          # float, cached
ctx.perf_stats()          # pd.Series, all cached
ctx.to_json('report.json')

# 层级2：函数式 API（不需要实例化）
from fincore.metrics.ratios import sharpe_ratio
sr = sharpe_ratio(returns, risk_free=0.02)

# 层级3：兼容 API（向后兼容老代码）
from fincore import Empyrical
Empyrical.sharpe_ratio(returns)  # 仍可用
emp = Empyrical(returns=returns)
emp.sharpe_ratio()               # 仍可用
```

### 5.2 简化 `Empyrical` 为兼容层

不删除 `Empyrical` 类，但将其简化为 `AnalysisContext` 的薄包装：

```python
# empyrical.py (simplified)
class Empyrical:
    """向后兼容接口。推荐使用 fincore.analyze() 代替。"""

    def __init__(self, returns=None, **kwargs):
        from fincore.core.context import AnalysisContext
        self._ctx = AnalysisContext(returns, **kwargs) if returns is not None else None
        self.returns = returns
        # ... 保留其他属性

    # 所有 @classmethod 直接委托到 metrics 函数（不变）
    @classmethod
    def sharpe_ratio(cls, returns, risk_free=0, period=DAILY, annualization=None, out=None):
        from fincore.metrics.ratios import sharpe_ratio
        return sharpe_ratio(returns, risk_free, period, annualization, out)

    # 所有 @_dual_method 实例方法优先查缓存
    @_dual_method
    def max_drawdown(self, returns=None):
        if self._ctx is not None and returns is None:
            return self._ctx.max_drawdown
        returns = self._get_returns(returns)
        from fincore.metrics.drawdown import max_drawdown
        return max_drawdown(returns)
```

### 5.3 废弃警告

对旧接口添加废弃警告（可选，可推迟到 v0.3）：

```python
import warnings

def _deprecation_warning(old_name, new_name):
    warnings.warn(
        f"{old_name} is deprecated. Use {new_name} instead.",
        DeprecationWarning, stacklevel=3)
```

---

## 阶段六：性能加速（P2-P3，持续）

### 6.1 `calc_bootstrap` 向量化

**当前代码** (`perf_stats.py:230-238`): 1000 次 Python for 循环。

**重构**:

```python
def calc_bootstrap(func, returns, *args, **kwargs):
    n_samples = kwargs.pop("n_samples", 1000)
    random_seed = kwargs.pop("random_seed", None)
    factor_returns = kwargs.pop("factor_returns", None)
    rng = np.random.RandomState(seed=random_seed)

    n = len(returns)
    # 一次性生成所有随机索引 — shape: (n_samples, n)
    all_idx = rng.randint(n, size=(n_samples, n))

    out = np.empty(n_samples)
    returns_arr = np.asanyarray(returns)
    factor_arr = np.asanyarray(factor_returns) if factor_returns is not None else None

    for i in range(n_samples):
        idx = all_idx[i]
        # 使用数组索引避免 .iloc 开销
        returns_i = pd.Series(returns_arr[idx])
        if factor_arr is not None:
            factor_i = pd.Series(factor_arr[idx])
            out[i] = func(returns_i, factor_i, *args, **kwargs)
        else:
            out[i] = func(returns_i, *args, **kwargs)

    return out
```

**进一步优化**: 对于可以在 numpy 数组上计算的函数（如 `sharpe_ratio`、`max_drawdown`），可以完全避免 pandas 开销：

```python
# 批量 bootstrap sharpe_ratio — 无 pandas 开销
def _bootstrap_sharpe_vectorized(returns_arr, n_samples, rng, ann_factor):
    n = len(returns_arr)
    idx = rng.randint(n, size=(n_samples, n))
    samples = returns_arr[idx]  # shape: (n_samples, n)
    means = samples.mean(axis=1)
    stds = samples.std(axis=1, ddof=1)
    with np.errstate(divide='ignore', invalid='ignore'):
        return (means / stds) * np.sqrt(ann_factor)
```

### 6.2 `get_top_drawdowns` 优化

**当前问题**: 逐个剥离回撤区间，每次调用 `get_max_drawdown_underwater` + `underwater.drop()`，O(top * n)。

**优化思路**: 用连通区间标记一次性找到所有回撤区间：

```python
def get_top_drawdowns_fast(returns, top=10):
    """一次性标记所有回撤区间并按深度排序。"""
    df_cum = cum_returns(returns, starting_value=1.0)
    running_max = np.maximum.accumulate(df_cum.values)
    underwater = df_cum.values / running_max - 1.0

    # 标记回撤区间
    is_dd = underwater < 0
    if not is_dd.any():
        return []

    # 找到每个连续回撤区间的边界
    diff = np.diff(is_dd.astype(int), prepend=0, append=0)
    starts = np.where(diff == 1)[0]
    ends = np.where(diff == -1)[0]

    # 每个区间的最大回撤深度
    periods = []
    idx = df_cum.index
    for s, e in zip(starts, ends):
        trough_pos = s + np.argmin(underwater[s:e])
        depth = underwater[trough_pos]
        peak = idx[max(0, s - 1)]
        valley = idx[trough_pos]
        recovery = idx[e] if e < len(idx) else pd.NaT
        periods.append((depth, peak, valley, recovery))

    # 按深度排序（最深的在前）
    periods.sort(key=lambda x: x[0])

    return [(p, v, r) for _, p, v, r in periods[:top]]
```

**预期收益**: 从 O(top * n) 降至 O(n)，对于 top=10, n=2520 可提速 5-10x。

---

## 阶段七：测试与 CI（贯穿所有阶段）

### 7.1 测试文件结构

```
tests/
├── test_core/
│   ├── test_context.py            # AnalysisContext 单元测试
│   ├── test_engine.py             # RollingEngine 单元测试
│   └── test_context_compat.py     # 验证与 Empyrical 结果一致
├── benchmarks/
│   ├── bench_perf_stats.py        # perf_stats 性能基准
│   ├── bench_rolling.py           # 滚动计算性能基准
│   └── bench_bootstrap.py         # bootstrap 性能基准
├── test_empyrical/                # 现有测试（不动）
└── test_pyfolio/                  # 现有测试（不动）
```

### 7.2 性能基准测试模板

```python
# tests/benchmarks/bench_perf_stats.py
import pytest
import numpy as np
import pandas as pd

@pytest.fixture
def sample_returns():
    np.random.seed(42)
    return pd.Series(np.random.randn(2520) * 0.01,
                     index=pd.bdate_range('2010-01-01', periods=2520))

def test_perf_stats_standalone(benchmark, sample_returns):
    from fincore.metrics.perf_stats import perf_stats
    benchmark(perf_stats, sample_returns)

def test_perf_stats_context(benchmark, sample_returns):
    from fincore.core.context import AnalysisContext
    ctx = AnalysisContext(sample_returns)
    benchmark(ctx.perf_stats)

def test_perf_stats_context_cached(benchmark, sample_returns):
    from fincore.core.context import AnalysisContext
    ctx = AnalysisContext(sample_returns)
    ctx.perf_stats()  # warm up cache
    benchmark(ctx.perf_stats)
```

运行: `pytest tests/benchmarks/ --benchmark-only --benchmark-sort=mean`

### 7.3 一致性回归测试

```python
# tests/test_core/test_context_compat.py
"""Ensure AnalysisContext produces identical results to standalone functions."""
import numpy as np
import pandas as pd
import pytest
from fincore.core.context import AnalysisContext
from fincore.metrics.perf_stats import perf_stats as standalone_perf_stats

@pytest.fixture
def data():
    np.random.seed(42)
    returns = pd.Series(np.random.randn(504) * 0.01,
                        index=pd.bdate_range('2020-01-01', periods=504))
    benchmark = pd.Series(np.random.randn(504) * 0.008,
                          index=returns.index)
    return returns, benchmark

def test_perf_stats_identical(data):
    returns, benchmark = data
    ctx = AnalysisContext(returns, factor_returns=benchmark)
    ctx_stats = ctx.perf_stats()
    standalone = standalone_perf_stats(returns, factor_returns=benchmark)

    for key in standalone.index:
        if key in ctx_stats.index:
            np.testing.assert_allclose(
                ctx_stats[key], standalone[key], rtol=1e-10,
                err_msg=f"Mismatch in {key}")
```

### 7.4 GitHub Actions CI

```yaml
# .github/workflows/ci.yml
name: CI
on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ['3.9', '3.10', '3.11', '3.12']
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
      - run: pip install -e ".[dev,viz]"
      - run: ruff check fincore/
      - run: mypy fincore/metrics/basic.py fincore/metrics/returns.py
      - run: pytest tests/ -n auto --cov=fincore --cov-report=xml
      - uses: codecov/codecov-action@v3
```

---

## 重构风险管理

| 阶段 | 风险 | 缓解措施 |
|------|------|---------|
| 1.1 依赖清理 | 移除 six 后某些遗留代码路径失效 | 先 grep 全项目确认 six 未被直接使用 |
| 1.2 惰性导入 | 循环导入 | 逐步迁移，每改一个模块立即运行完整测试 |
| 1.3 类型定义 | NamedTuple 替换 tuple 导致序列化/pickle 不兼容 | NamedTuple 完全兼容 tuple 解构，风险极低 |
| 2.2 AnalysisContext | 缓存值过期（数据被外部修改） | 提供 `invalidate()` 方法；文档说明不可变语义 |
| 3.1 向量化 roll_max_drawdown | 大数据内存占用 | 提供 chunk 模式回退 |
| 4.x 可视化解耦 | 现有 tearsheet 参数繁多 | 不改现有函数签名，新后端仅包装调用 |
| 5.x God Class 拆分 | 下游用户代码依赖 Empyrical 接口 | 保留 Empyrical 作为兼容层，永不删除 |

---

## 里程碑检查点

| 里程碑 | 完成标志 | 预计时间 |
|--------|---------|---------|
| M1: 依赖清理 | `pip install -e .` 无 six；`import fincore` < 0.1s | 第1周 |
| M2: 类型基础 | `_types.py` 创建；`basic.py` + `returns.py` 添加 type hints | 第2周 |
| M3: AnalysisContext | `fincore.analyze(returns).perf_stats()` 可用；性能测试通过 | 第4周 |
| M4: 向量化 | `roll_max_drawdown` 提速 10x+；基准测试建立 | 第5周 |
| M5: 可视化后端 | `ctx.plot(backend='matplotlib')` 可用 | 第8周 |
| M6: HTML 报告 | `ctx.to_html('report.html')` 可用 | 第9周 |
| M7: 顶级 API | `fincore.analyze()` 作为主推 API | 第10周 |
| M8: CI/CD | GitHub Actions 全绿；覆盖率 > 85% | 第12周 |

---

## 总结

本重构计划的核心思路：

1. **不破坏现有接口** — `Empyrical` 和 `Pyfolio` 永远可用
2. **新增更好的接口** — `fincore.analyze()` 成为推荐入口
3. **性能通过缓存提升** — `AnalysisContext` 的 `cached_property` 消除重复计算
4. **渐进式迁移** — 每个阶段独立可交付、可验证、可回退
5. **最终目标** — 3 行代码完成完整绩效分析，性能比现在快 5-10x

```python
import fincore
ctx = fincore.analyze(returns, factor_returns=benchmark)
ctx.perf_stats().to_frame().to_html('report.html')
```

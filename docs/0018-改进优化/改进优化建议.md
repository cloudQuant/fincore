### 背景
当前项目已经初步完成，主要基于empyrical和pyfolio这两个包进行了合并和优化，并且现在已经做了很多的修复bug和改进优化的工作。

### 任务

1. 分析现在整体上的项目架构
2. 希望给出整体上架构的优化建议，提高整体上的运行效率和速度
3. 给出详细的重构建议，使得整个绩效评估的项目能够达到世界最顶级的水平。

---

## 一、当前项目架构分析

### 1.1 整体结构

```
fincore/
├── __init__.py            # 入口：导出 Empyrical, Pyfolio
├── empyrical.py           # 1233行，God Class，~120个方法的门面
├── pyfolio.py             # 830行，继承Empyrical，绑定所有绘图方法
├── constants/             # 常量定义 (DAILY, 颜色, 样式, 有趣日期范围)
├── metrics/               # 核心计算引擎 (17个模块, ~250KB)
│   ├── basic.py           # 基础工具 (aligned_series, annualization_factor)
│   ├── returns.py         # 收益计算 (cum_returns, simple_returns)
│   ├── drawdown.py        # 回撤分析 (20KB, 功能最重)
│   ├── risk.py            # 风险指标 (VaR, CVaR, volatility, tracking_error)
│   ├── ratios.py          # 比率指标 (Sharpe, Sortino, Calmar 等20+比率)
│   ├── alpha_beta.py      # Alpha/Beta (对齐版+非对齐版, 年度拆分)
│   ├── stats.py           # 统计指标 (Hurst, skewness, 相关性)
│   ├── consecutive.py     # 连续涨跌 (日/周/月粒度)
│   ├── rolling.py         # 滚动计算 (roll_alpha, roll_beta 等)
│   ├── bayesian.py        # 贝叶斯模型 (PyMC依赖)
│   ├── perf_stats.py      # 综合绩效统计 (perf_stats, bootstrap)
│   ├── perf_attrib.py     # 因子归因
│   ├── positions.py       # 持仓分析
│   ├── transactions.py    # 交易分析
│   ├── round_trips.py     # 往返交易
│   ├── timing.py          # 市场择时
│   └── yearly.py          # 按年统计
├── tearsheets/            # 可视化层 (10个模块, ~120KB)
│   ├── sheets.py          # 11个tearsheet入口函数
│   ├── returns.py         # 收益相关图表
│   ├── positions.py       # 持仓相关图表
│   └── ...
├── utils/                 # 工具函数
│   ├── common_utils.py    # 27KB，杂项函数集合
│   ├── data_utils.py      # 数据加载
│   ├── math_utils.py      # nanmean, nanstd
│   └── deprecate.py       # 废弃装饰器
└── datas/                 # 静态数据文件
```

### 1.2 架构特征与问题

#### A. God Class 反模式

`Empyrical` 类（1233行，~120个方法）是一个典型的 **God Class**：

- 它不持有有意义的状态（仅 `returns`, `positions`, `factor_returns`, `factor_loadings`）
- 绝大多数方法是 `@classmethod` 或 `@staticmethod`，仅做一层委托转发
- `_dual_method` 描述符增加了理解和维护的复杂度
- `Pyfolio` 继承 `Empyrical`，再绑定 ~50 个绘图方法，形成 ~170 方法的超大类

**影响**: 新用户需要在一个巨大接口中寻找所需方法；IDE自动补全被海量方法淹没；方法分组仅靠注释分隔，没有类型层面的约束。

#### B. 过度间接层

调用链路过长：
```
用户 → Empyrical.sharpe_ratio()     # empyrical.py, 纯转发
     → _ratios.sharpe_ratio()        # metrics/__init__.py 中转
     → ratios.sharpe_ratio()          # 实际实现
```

`metrics/__init__.py` 把 17 个模块全部导入为 `xxx_module`，然后 `empyrical.py` 又全部重新导入为 `_xxx`。两层别名增加了跳转和理解的成本，但没有带来实际价值。

#### C. 计算层无缓存

- 每次调用 `perf_stats()` 会重新计算 ~30 个指标，许多指标（如 `annual_return`, `max_drawdown`, `annual_volatility`）被多个比率指标重复调用
- `gen_drawdown_table()` 内部 `get_top_drawdowns()` 会多次调用 `cum_returns()`
- 滚动函数 (`roll_alpha`, `roll_max_drawdown`) 使用 Python for 循环逐窗口调用，部分由于非线性年化公式无法向量化

#### D. 可视化与计算耦合

`tearsheets/sheets.py`（35KB）中 `create_full_tear_sheet` 等函数同时负责：
1. 数据验证和预处理
2. 指标计算
3. 图表布局和渲染
4. 结果展示

这导致无法在不绘图的情况下获取结构化的分析结果（例如导出为JSON/HTML报告）。

#### E. 依赖管理问题

- `requirements.txt` 混合了核心依赖、可选依赖、测试依赖、遗留依赖
- `six` 仍在 `install_requires` 中（Python 2/3兼容层，Python 3.8+ 不需要）
- `pymc` 作为硬依赖出现在 `requirements.txt` 中（实际上只有 bayesian 模块使用）
- `setup.py` 和 `pyproject.toml` 并存但配置不一致

#### F. 类型信息缺失

- 所有函数签名缺少类型注解（type hints）
- 返回类型不一致：同一函数可能返回 `float`, `np.nan`, `pd.Series`, 或 `np.ndarray`
- 没有利用 `Protocol` 或 `TypeVar` 来约束输入类型

---

## 二、架构优化建议 — 提高运行效率和速度

### 2.1 引入计算结果缓存层（高优先级）

**问题**: `perf_stats()` 每次调用重算 30+ 指标，`gen_drawdown_table()` 重复计算累积收益。

**方案**: 引入 `AnalysisContext` 计算上下文，缓存中间结果。

```python
class AnalysisContext:
    """Lazy-compute + cache analytics results for a single returns series."""

    def __init__(self, returns: pd.Series, factor_returns=None,
                 risk_free=0.0, period=DAILY):
        self._returns = returns
        self._factor_returns = factor_returns
        self._risk_free = risk_free
        self._period = period
        self._cache: dict[str, Any] = {}

    @cached_property
    def cum_returns(self) -> pd.Series:
        return cum_returns(self._returns, starting_value=1.0)

    @cached_property
    def underwater(self) -> pd.Series:
        running_max = self.cum_returns.expanding().max()
        return self.cum_returns / running_max - 1

    @cached_property
    def annual_return(self) -> float:
        return annual_return(self._returns, self._period)

    @cached_property
    def max_drawdown(self) -> float:
        return max_drawdown(self._returns)

    @cached_property
    def sharpe_ratio(self) -> float:
        return sharpe_ratio(self._returns, self._risk_free, self._period)

    def perf_stats(self) -> pd.Series:
        """Build perf stats from cached properties — no redundant computation."""
        return pd.Series({
            'Annual return': self.annual_return,
            'Max drawdown': self.max_drawdown,
            'Sharpe ratio': self.sharpe_ratio,
            # ...
        })
```

**预期收益**: `perf_stats()` 和 tearsheet 生成速度提升 **2-3x**（消除 `cum_returns`, `annual_return`, `max_drawdown` 等被调用 5-10 次的重复计算）。

### 2.2 批量滚动计算引擎（高优先级）

**问题**: `roll_alpha`, `roll_max_drawdown`, `roll_up_capture`, `roll_down_capture` 等函数各自独立用 Python for 循环遍历所有窗口。

**方案**: 构建统一的 `RollingEngine`，单次遍历同时输出多个滚动指标。

```python
class RollingEngine:
    """Single-pass rolling computation for multiple metrics."""

    def __init__(self, returns, factor_returns=None, window=252, risk_free=0.0):
        self._ret = returns
        self._fac = factor_returns
        self._win = window
        self._rf = risk_free

    def compute(self, metrics: list[str]) -> pd.DataFrame:
        """Compute requested rolling metrics in a single window sweep."""
        n = len(self._ret) - self._win + 1
        results = {m: np.empty(n) for m in metrics}

        for i in range(n):
            r = self._ret.iloc[i:i+self._win]
            f = self._fac.iloc[i:i+self._win] if self._fac is not None else None
            for m in metrics:
                results[m][i] = self._compute_one(m, r, f)

        idx = self._ret.index[self._win - 1:]
        return pd.DataFrame(results, index=idx)
```

**预期收益**: 当同时需要 roll_alpha + roll_beta + roll_sharpe + roll_max_drawdown 时（tearsheet 常见场景），减少 **4x** 的窗口遍历开销。

### 2.3 NumPy Strided 批量窗口（中优先级）

**问题**: 部分滚动函数可以用 `np.lib.stride_tricks.sliding_window_view` 预切片后批量计算。

**方案**: 对可向量化的指标（`roll_beta`, `rolling_volatility`, `rolling_sharpe`），用 stride view 替代 for 循环：

```python
from numpy.lib.stride_tricks import sliding_window_view

def roll_max_drawdown_vectorized(returns, window):
    """Vectorized rolling max drawdown using strided windows."""
    arr = np.asarray(returns)
    windows = sliding_window_view(arr, window)  # shape: (n-w+1, w)
    cum = np.cumprod(1 + windows, axis=1)
    running_max = np.maximum.accumulate(cum, axis=1)
    underwater = cum / running_max - 1
    return pd.Series(underwater.min(axis=1), index=returns.index[window-1:])
```

**预期收益**: `roll_max_drawdown` 提速 **10-50x**（纯 NumPy 操作 vs Python for 循环）。同理适用于 `rolling_volatility`。

### 2.4 可选 Numba JIT 加速（中优先级）

**问题**: `alpha_aligned`/`beta_aligned` 内部有大量 numpy 临时数组分配；`get_top_drawdowns` 的迭代剥离逻辑是纯 Python。

**方案**: 为热点路径提供 Numba 加速版本（渐进式，不引入硬依赖）：

```python
try:
    from numba import njit

    @njit(cache=True)
    def _beta_aligned_numba(returns, factor_returns, risk_free):
        n = len(returns)
        ret = returns - risk_free
        fac = factor_returns - risk_free
        fac_mean = 0.0
        for i in range(n):
            if not np.isnan(fac[i]):
                fac_mean += fac[i]
        fac_mean /= n
        cov = var = 0.0
        for i in range(n):
            d = fac[i] - fac_mean
            cov += d * ret[i]
            var += d * d
        return cov / var if var > 1e-30 else np.nan

except ImportError:
    _beta_aligned_numba = None  # fallback to numpy version
```

**预期收益**: `beta_aligned` 提速 **3-5x**（消除临时数组分配）；`calc_bootstrap` 的 1000 次重采样提速 **5-10x**。

### 2.5 惰性导入（低优先级但立竿见影）

**问题**: `import fincore` 会触发整条导入链：`empyrical.py` → `metrics/__init__.py`（17 个子模块全部导入）→ `pyfolio.py`（matplotlib, seaborn, IPython 等重量级依赖）。

**方案**: 改为惰性导入，仅在实际使用时加载：

```python
# fincore/__init__.py
import importlib

def __getattr__(name):
    if name == "Empyrical":
        from .empyrical import Empyrical
        return Empyrical
    if name == "Pyfolio":
        from .pyfolio import Pyfolio
        return Pyfolio
    raise AttributeError(f"module 'fincore' has no attribute {name}")
```

**预期收益**: `import fincore` 从 ~1.5s 降至 ~0.05s；仅在调用计算或绘图时才加载相应模块。

---

## 三、详细重构建议 — 世界顶级水平

### 3.1 核心理念

世界顶级的绩效分析库（参考 QuantStats、vectorbt、ffn）具备以下特征：

1. **极简 API** — 用户 3 行代码完成完整分析
2. **零冗余计算** — 相同数据只算一次
3. **多输出格式** — DataFrame / HTML报告 / PDF / JSON / 交互式
4. **流式/增量计算** — 支持实时数据追加而非全量重算
5. **类型安全** — 完整的 type hints + 运行时验证
6. **可扩展** — 用户可注册自定义指标
7. **高性能** — 数百万行数据秒级响应

### 3.2 目标架构

```
fincore/
├── __init__.py                    # 惰性导出
├── _types.py                      # 类型定义 (TypeAlias, Protocol)
├── core/                          # 核心计算引擎
│   ├── context.py                 # AnalysisContext (缓存+惰性计算)
│   ├── registry.py                # 指标注册表 (用户可扩展)
│   └── engine.py                  # RollingEngine / BatchEngine
├── metrics/                       # 纯函数指标 (无状态，可独立使用)
│   ├── returns.py                 # 收益
│   ├── drawdown.py                # 回撤
│   ├── risk.py                    # 风险
│   ├── ratios.py                  # 比率
│   ├── alpha_beta.py              # Alpha/Beta
│   ├── stats.py                   # 统计
│   ├── rolling.py                 # 滚动
│   ├── timing.py                  # 择时
│   └── bayesian.py                # 贝叶斯 (可选依赖)
├── analysis/                      # 结构化分析结果
│   ├── report.py                  # AnalysisReport (DataFrame/dict/JSON)
│   ├── tearsheet.py               # TearSheet (分离计算与渲染)
│   └── comparison.py              # 多策略对比
├── portfolio/                     # 组合分析
│   ├── positions.py
│   ├── transactions.py
│   ├── round_trips.py
│   └── attribution.py
├── viz/                           # 纯可视化层 (接收计算结果，不做计算)
│   ├── matplotlib_backend.py
│   ├── plotly_backend.py          # 新增：交互式图表
│   └── html_backend.py            # 新增：HTML报告
├── io/                            # 输入/输出
│   ├── loaders.py                 # 数据加载
│   └── exporters.py               # JSON / CSV / HTML / PDF 导出
├── constants.py                   # 单文件常量
└── compat.py                      # 向后兼容层 (Empyrical/Pyfolio别名)
```

### 3.3 重构步骤路线图

#### 阶段一：类型安全 + 依赖清理（1-2周）

**目标**: 不改变 API，提升代码质量和可维护性。

| 任务 | 详情 | 优先级 |
|------|------|--------|
| 添加 type hints | 所有公开函数添加参数和返回值类型注解 | 高 |
| 创建 `_types.py` | `ReturnSeries = pd.Series`, `DrawdownResult = NamedTuple(peak, valley, recovery)` | 高 |
| 清理 `requirements.txt` | 移除 `six`；`pymc` 移入 `extras_require["bayesian"]`；分离 dev/test/optional | 高 |
| 迁移到纯 `pyproject.toml` | 移除 `setup.py`，使用现代 PEP 621 配置 | 中 |
| 配置 `mypy` | 添加 `mypy.ini`，逐模块启用类型检查 | 中 |
| 配置 `ruff` | 统一代码风格，替代 flake8 | 低 |

```python
# _types.py 示例
from typing import NamedTuple, Optional, Union
import numpy as np
import pandas as pd

ReturnSeries = Union[pd.Series, np.ndarray]
DrawdownPeriod = NamedTuple('DrawdownPeriod', [
    ('peak', pd.Timestamp),
    ('valley', pd.Timestamp),
    ('recovery', Optional[pd.Timestamp]),
])
```

#### 阶段二：AnalysisContext 缓存层（2-3周）

**目标**: 消除重复计算，保持 API 向后兼容。

```python
# core/context.py
from functools import cached_property

class AnalysisContext:
    """Core analysis context with lazy computation and caching."""

    def __init__(self, returns, factor_returns=None, positions=None,
                 risk_free=0.0, period='daily'):
        self.returns = returns
        self.factor_returns = factor_returns
        self.positions = positions
        self.risk_free = risk_free
        self.period = period

    def invalidate(self):
        """Clear all cached results (e.g., after data update)."""
        for attr in list(self.__dict__):
            if isinstance(getattr(type(self), attr, None), cached_property):
                del self.__dict__[attr]

    @cached_property
    def cum_returns(self):
        return cum_returns(self.returns, starting_value=1.0)

    @cached_property
    def _underwater(self):
        rm = self.cum_returns.expanding().max()
        return self.cum_returns / rm - 1

    @cached_property
    def max_drawdown(self):
        return self._underwater.min()

    @cached_property
    def annual_return(self):
        return annual_return(self.returns, self.period)

    @cached_property
    def annual_volatility(self):
        return annual_volatility(self.returns, self.period)

    @cached_property
    def sharpe_ratio(self):
        return sharpe_ratio(self.returns, self.risk_free, self.period)

    @cached_property
    def alpha_beta(self):
        if self.factor_returns is None:
            return (np.nan, np.nan)
        return alpha_beta(self.returns, self.factor_returns,
                         self.risk_free, self.period)

    @cached_property
    def top_drawdowns(self):
        return get_top_drawdowns(self.returns, top=10)

    def perf_stats(self) -> pd.Series:
        """All stats computed exactly once via cached_property."""
        stats = {
            'Annual return': self.annual_return,
            'Cumulative returns': cum_returns_final(self.returns),
            'Annual volatility': self.annual_volatility,
            'Sharpe ratio': self.sharpe_ratio,
            'Calmar ratio': self.annual_return / abs(self.max_drawdown)
                            if self.max_drawdown != 0 else np.nan,
            'Max drawdown': self.max_drawdown,
            'Omega ratio': omega_ratio(self.returns, self.risk_free),
            'Sortino ratio': sortino_ratio(self.returns, period=self.period),
            'Skew': skewness(self.returns),
            'Kurtosis': kurtosis(self.returns),
            'Tail ratio': tail_ratio(self.returns),
            'Alpha': self.alpha_beta[0],
            'Beta': self.alpha_beta[1],
        }
        return pd.Series(stats)
```

**向后兼容**: `Empyrical` 类可以内部使用 `AnalysisContext`：
```python
class Empyrical:
    def __init__(self, returns=None, **kwargs):
        self._ctx = AnalysisContext(returns, **kwargs) if returns is not None else None

    @_dual_method
    def sharpe_ratio(self, returns=None, ...):
        if self._ctx is not None and returns is None:
            return self._ctx.sharpe_ratio  # cached
        return _ratios.sharpe_ratio(returns, ...)  # standalone
```

#### 阶段三：拆分 God Class（2-3周）

**目标**: 将 `Empyrical` 拆分为职责清晰的小模块，同时保留兼容层。

```python
# 新的顶级 API
import fincore

# 方式1：函数式 (直接调用metrics函数)
from fincore.metrics import sharpe_ratio, max_drawdown
sr = sharpe_ratio(returns)
dd = max_drawdown(returns)

# 方式2：上下文式 (推荐，带缓存)
ctx = fincore.analyze(returns, factor_returns=benchmark)
print(ctx.sharpe_ratio)      # cached_property
print(ctx.max_drawdown)      # cached_property
print(ctx.perf_stats())      # 汇总，无重复计算

# 方式3：报告式
report = ctx.to_report()     # -> AnalysisReport
report.to_html("report.html")
report.to_json("report.json")
report.to_dataframe()

# 方式4：兼容式 (向后兼容)
from fincore import Empyrical  # 仍可用
Empyrical.sharpe_ratio(returns)
```

#### 阶段四：可视化解耦（3-4周）

**目标**: 将计算与渲染彻底分离；支持多后端。

```python
# viz/base.py
class VizBackend(Protocol):
    def plot_returns(self, report: AnalysisReport, ax=None): ...
    def plot_drawdown(self, report: AnalysisReport, ax=None): ...
    def plot_rolling(self, report: AnalysisReport, metrics: list, ax=None): ...

# viz/matplotlib_backend.py
class MatplotlibBackend(VizBackend):
    def plot_returns(self, report, ax=None):
        if ax is None:
            fig, ax = plt.subplots()
        ax.plot(report.cum_returns)
        ax.set_title(f'Cumulative Returns (Sharpe: {report.sharpe_ratio:.2f})')
        return ax

# viz/plotly_backend.py
class PlotlyBackend(VizBackend):
    def plot_returns(self, report, fig=None):
        import plotly.graph_objects as go
        fig = fig or go.Figure()
        fig.add_trace(go.Scatter(x=report.cum_returns.index,
                                  y=report.cum_returns.values))
        return fig

# 用户使用
ctx = fincore.analyze(returns)
ctx.plot(backend="matplotlib")  # 默认
ctx.plot(backend="plotly")      # 交互式
ctx.to_html("report.html")     # 静态HTML报告
```

**tearsheet 重构**:
```python
# analysis/tearsheet.py
class TearSheet:
    def __init__(self, ctx: AnalysisContext, backend: VizBackend = None):
        self.ctx = ctx
        self.backend = backend or MatplotlibBackend()

    def create_returns_sheet(self):
        report = self.ctx.to_report()
        self.backend.plot_returns(report)
        self.backend.plot_drawdown(report)
        self.backend.plot_rolling(report, ['sharpe', 'volatility'])

    def create_full_sheet(self):
        self.create_returns_sheet()
        if self.ctx.positions is not None:
            self.create_positions_sheet()
        # ...
```

#### 阶段五：自定义指标注册 + 增量计算（4-6周）

**目标**: 用户可以注册自定义指标并无缝集成到分析流程中。

```python
# core/registry.py
from typing import Callable

_METRIC_REGISTRY: dict[str, Callable] = {}

def register_metric(name: str, requires: list[str] = None):
    """Decorator to register a custom metric."""
    def decorator(func):
        _METRIC_REGISTRY[name] = {
            'func': func,
            'requires': requires or [],
        }
        return func
    return decorator

# 用户自定义
@register_metric('my_ratio', requires=['annual_return', 'max_drawdown'])
def my_ratio(ctx):
    return ctx.annual_return / (abs(ctx.max_drawdown) + 0.01)

# 自动出现在 perf_stats 中
ctx = fincore.analyze(returns)
stats = ctx.perf_stats(include=['my_ratio'])
```

**增量计算** (适用于实时交易场景):
```python
class StreamingContext(AnalysisContext):
    """Supports incremental data append without full recomputation."""

    def append(self, new_returns: pd.Series):
        """Append new data and invalidate affected caches."""
        self.returns = pd.concat([self.returns, new_returns])
        # Smart invalidation: only clear caches that depend on full series
        self._invalidate_rolling_caches()
        # Running stats (mean, var) can be updated incrementally
        self._update_running_stats(new_returns)
```

### 3.4 性能优化细节清单

| 优化项 | 当前状态 | 目标 | 预期提速 |
|--------|---------|------|----------|
| `perf_stats` 重复计算 | 30+ 指标各自独立计算 | `AnalysisContext` 缓存 | 2-3x |
| `roll_max_drawdown` | Python for 循环 | `sliding_window_view` + vectorized | 10-50x |
| `roll_up/down_capture` | Python for 循环 | 批量窗口 + 缓存 | 5-10x |
| `calc_bootstrap` | Python for 循环 | Numba JIT / vectorized resample | 5-10x |
| `get_top_drawdowns` | 迭代剥离 + 多次 cum_returns | 单次 cummax + 连通区间标记 | 3-5x |
| `beta_aligned` | 多次临时数组分配 | Numba 单遍扫描 / `out` 参数复用 | 2-3x |
| `import fincore` 冷启动 | 全量导入 matplotlib/seaborn | 惰性导入 | 30x |
| `aligned_series` | 每次 concat + outer join | 调用方预对齐 + 缓存结果 | 2x |

### 3.5 测试与质量保障

| 维度 | 当前 | 建议 |
|------|------|------|
| 覆盖率 | 未度量 | 添加 `pytest-cov`，目标 >90% |
| 基准测试 | `pytest-benchmark` 已安装但未使用 | 为每个 metrics 函数添加基准用例 |
| 属性测试 | 无 | 使用 `hypothesis` 生成随机收益序列，验证指标不变量 |
| 回归测试 | 无 | 固定种子生成标准数据集，保存预期结果为 golden files |
| CI | 无 | GitHub Actions: lint → type-check → test → benchmark |
| 文档 | 中文 docstring | 添加 Sphinx + autodoc，生成API文档网站 |

### 3.6 与世界顶级库的对比及差距

| 维度 | QuantStats | vectorbt | **fincore (当前)** | **fincore (目标)** |
|------|------------|----------|--------------------|--------------------|
| 指标数量 | ~30 | ~20 | **~80+** ✅ | ~100+ |
| 一行报告 | ✅ `qs.reports.html()` | ✅ `pf.stats()` | ❌ 需多步 | ✅ `ctx.to_html()` |
| 缓存 | ❌ | ✅ | ❌ | ✅ `AnalysisContext` |
| 交互式图表 | ❌ | ✅ Plotly | ❌ | ✅ 多后端 |
| 增量计算 | ❌ | ✅ | ❌ | ✅ `StreamingContext` |
| 类型安全 | ❌ | 部分 | ❌ | ✅ 完整 type hints |
| 自定义指标 | ❌ | ✅ | ❌ | ✅ 注册表 |
| Numba加速 | ❌ | ✅ | ❌ | ✅ 可选 |
| HTML报告 | ✅ | ❌ | ❌ | ✅ |
| 因子归因 | ❌ | ❌ | **✅** | ✅ |
| 贝叶斯分析 | ❌ | ❌ | **✅** | ✅ |
| 往返交易分析 | ❌ | ❌ | **✅** | ✅ |

**fincore 的独特优势**: 因子归因、贝叶斯分析、往返交易分析、市场择时检验 — 这些是 QuantStats 和 vectorbt 都不提供的高级功能。重构后保留这些优势，同时补齐缓存/类型/可视化/易用性短板，可以成为最全面的量化绩效分析库。

---

## 四、实施优先级排序

### P0 — 立即执行（1周内）

1. **清理依赖**: 移除 `six`，`pymc` → optional，分离 requirements 文件
2. **惰性导入**: `fincore/__init__.py` 改为 `__getattr__` 模式
3. **添加 type hints**: 从 `basic.py`, `returns.py` 开始，逐文件添加
4. **迁移到纯 `pyproject.toml`**

### P1 — 短期（2-4周）

5. **实现 `AnalysisContext`**: 缓存层，覆盖 `perf_stats` 常用的 15 个指标
6. **向量化 `roll_max_drawdown`**: 用 `sliding_window_view` 替代 for 循环
7. **添加 `pytest-cov` 和基准测试**: 建立性能基线
8. **统一返回类型**: 用 `NamedTuple` 替代 tuple 返回

### P2 — 中期（1-2月）

9. **拆分 God Class**: 提取 `fincore.analyze()` 顶级 API
10. **可视化解耦**: 抽象 `VizBackend`，支持 Plotly
11. **HTML 报告生成器**: `ctx.to_html()`
12. **指标注册表**: 支持用户自定义指标

### P3 — 长期（2-3月）

13. **增量/流式计算**: `StreamingContext`
14. **Numba 可选加速**: 热点路径 JIT 编译
15. **Sphinx 文档网站**: 完整 API 文档 + 使用示例
16. **多策略对比**: `fincore.compare([ctx1, ctx2, ctx3])`

---

## 五、总结

fincore 当前拥有 **80+ 量化指标**（远超 QuantStats 的 30 个），且覆盖因子归因、贝叶斯分析、往返交易等高级场景，功能深度已处于顶级水平。主要差距在于：

1. **工程质量**: God Class 模式、缺乏类型注解、依赖混乱
2. **运行效率**: 无缓存导致重复计算、滚动函数缺乏向量化
3. **用户体验**: 无一行式 API、无 HTML 报告、无交互式图表
4. **可扩展性**: 无自定义指标注册、无增量计算

通过上述四阶段重构，fincore 可以在保持功能领先的同时，在工程质量、性能和易用性上达到世界顶级水平，成为 Python 量化绩效分析的标杆库。